<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Akash Girme's Blog</title><link>https://blog.akashgirme.com/</link><description>Recent content on Akash Girme's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 23 Mar 2023 00:00:00 +0530</lastBuildDate><atom:link href="https://blog.akashgirme.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Logging at Zerodha</title><link>https://blog.akashgirme.com/blog/logging-at-zerodha/</link><pubDate>Thu, 23 Mar 2023 00:00:00 +0530</pubDate><guid>https://blog.akashgirme.com/blog/logging-at-zerodha/</guid><description>At Zerodha, we run a multitude of internal and public-facing services that generate copious amounts of logs. While developers use these logs to debug or troubleshoot incidents, some services also emit logs that must be persisted for prolonged periods to comply with numerous regulatory requirements. In this post, I will delve into our experiences with the ELK stack, why it didn&amp;rsquo;t fit our needs and our migration to ClickHouse.
Why ELK wasnâ€™t the right fit for us In 2018, we adopted the ELK stack as our de facto stack for storing application logs.</description></item><item><title>Working with PostgreSQL</title><link>https://blog.akashgirme.com/blog/working-with-postgresql/</link><pubDate>Thu, 22 Apr 2021 00:00:00 +0530</pubDate><guid>https://blog.akashgirme.com/blog/working-with-postgresql/</guid><description>This post is in the context of the large, data heavy PostgreSQL instances that store historical transactional data and reports, the databases that power Console and its large scale number crunching and reporting. It talks about how we self-host, tune, and manage all our DB instances on bare EC2 instances. For high availability and backups, we use simple failover replicas and for backups, AWS disk snapshots.
The Console DBs store hundreds of billions of rows of different kinds of financial and transactional data, currently close to 20 TB, across four sharded nodes.</description></item><item><title>Hello, World!</title><link>https://blog.akashgirme.com/blog/hello-world/</link><pubDate>Mon, 06 Apr 2020 00:00:00 +0530</pubDate><guid>https://blog.akashgirme.com/blog/hello-world/</guid><description>Zerodha, now India&amp;rsquo;s largest stock broker, bootstrapped and profitable, turns ten years old this year. The Zerodha tech team turns seven years old. The tech team has remained largely elusive over the course of our existence. While we have pondered starting a tech blog for more than half a decade, we have often found ourselves too busy building the fundamental blocks underlying a stock brokerage. We have also been stalled by a sense of unpreparedness to talk to the world about our very unconventional setup.</description></item></channel></rss>